!pip install ucimlrepo
!pip install pycaret[full]
import pandas as pd
from ucimlrepo import fetch_ucirepo
from pycaret.clustering import *
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from ucimlrepo import fetch_ucirepo 
  
# Fetch the wine dataset 
wine = fetch_ucirepo(id=109) 
  
# data (as pandas dataframes) 
X = wine.data.features 
y = wine.data.targets 
  
# metadata 
print(wine.metadata) 
  
# variable information 
print(wine.variables) 

import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from pycaret.clustering import *

# Load the breast cancer dataset
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)

# Initialize an empty DataFrame to store the results
result_df = pd.DataFrame()

def evaluate(data, models, clusters, id=123):
    # No Pre-Processing
    for c in clusters:
        s = []
        setup(data=data, session_id=id, verbose=False)
        for model in models:
            df = assign_model(create_model(model, num_clusters=c)).dropna()
            X = df.drop(['Cluster'], axis=1)
            labels = df['Cluster']
            s.append(silhouette_score(X, labels))
            s.append(calinski_harabasz_score(X, labels))
            s.append(davies_bouldin_score(X, labels))
        result_df[f"A{c}"] = s

    # Using Normalization
    for c in clusters:
        s = []
        setup(data=data, session_id=id, normalize=True, normalize_method='zscore', verbose=False)
        for model in models:
            df = assign_model(create_model(model, num_clusters=c)).dropna()
            X = df.drop(['Cluster'], axis=1)
            labels = df['Cluster']
            s.append(silhouette_score(X, labels))
            s.append(calinski_harabasz_score(X, labels))
            s.append(davies_bouldin_score(X, labels))
        result_df[f"B{c}"] = s

    # Using Transformation
    for c in clusters:
        s = []
        setup(data=data, session_id=id, transformation=True, transformation_method='yeo-johnson', verbose=False)
        for model in models:
            df = assign_model(create_model(model, num_clusters=c)).dropna()
            X = df.drop(['Cluster'], axis=1)
            labels = df['Cluster']
            s.append(silhouette_score(X, labels))
            s.append(calinski_harabasz_score(X, labels))
            s.append(davies_bouldin_score(X, labels))
        result_df[f"C{c}"] = s

    # Using PCA
    for c in clusters:
        s = []
       X = df.drop(['Cluster'], axis=1)
            labels = df['Cluster']
            s.append(silhouette_score(X, labels))
            s.append(calinski_harabasz_score(X, labels))
            s.append(davies_bouldin_score(X, labels))
        result_df[f"D{c}"] = s

    # Using Transformation + Normalization
    for c in clusters:
        s = []
        setup(data=data, session_id=id, transformation=True, normalize=True,
              normalize_method='zscore', transformation_method='yeo-johnson', verbose=False)
        for model in models:
            df = assign_model(create_model(model, num_clusters=c)).dropna()
            X = df.drop(['Cluster'], axis=1)
            labels = df['Cluster']
            s.append(silhouette_score(X, labels))
            s.append(calinski_harabasz_score(X, labels))
            s.append(davies_bouldin_score(X, labels))
        result_df[f"E{c}"] = s

    # Using Transformation + Normalization + PCA
    for c in clusters:
        s = []
        setup(data=data, session_id=id, transformation=True, normalize=True,
              normalize_method='zscore', transformation_method='yeo-johnson', pca=True, pca_method='linear', verbose=False)
        for model in models:
            df = assign_model(create_model(model, num_clusters=c)).dropna()
            X = df.drop(['Cluster'], axis=1)
            labels = df['Cluster']
            s.append(silhouette_score(X, labels))
            s.append(calinski_harabasz_score(X, labels))
            s.append(davies_bouldin_score(X, labels))
        result_df[f"F{c}"] = s

# Specify clustering models and clusters
models = ["kmeans", "hclust", "birch", "optics"]
clusters = [3, 4, 5]

# Call the evaluate function with the wine dataset
evaluate(X, models, clusters)
   setup(data=data, session_id=id, pca=True, pca_method='linear', verbose=False)
        for model in models:
            df = assign_model(create_model(model, num_clusters=c)).dropna()
          